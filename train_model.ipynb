{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f444ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431464db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "IMAGE_SIZE = 320\n",
    "GRID_SIZE = 10\n",
    "CLASSES = [\"bottle\", \"person\"]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "IMG_DIR = r\"dataset\\datasetsss\"\n",
    "ANN_DIR = r\"dataset\\datasetannotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cfc2636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.1\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Images dir exists: True\n",
      "Annotations dir exists: True\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CHECK ENVIRONMENT\n",
    "# =========================\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Images dir exists:\", os.path.exists(IMG_DIR))\n",
    "print(\"Annotations dir exists:\", os.path.exists(ANN_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f35846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# XML PARSER\n",
    "# =========================\n",
    "def parse_xml(xml_file, img_w, img_h):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    label = np.zeros((GRID_SIZE, GRID_SIZE, 5 + NUM_CLASSES), dtype=np.float32)\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        if cls not in CLASSES:\n",
    "            continue\n",
    "\n",
    "        cls_id = CLASSES.index(cls)\n",
    "        box = obj.find(\"bndbox\")\n",
    "\n",
    "        xmin = int(box.find(\"xmin\").text)\n",
    "        ymin = int(box.find(\"ymin\").text)\n",
    "        xmax = int(box.find(\"xmax\").text)\n",
    "        ymax = int(box.find(\"ymax\").text)\n",
    "\n",
    "        xc = ((xmin + xmax) / 2) / img_w\n",
    "        yc = ((ymin + ymax) / 2) / img_h\n",
    "        bw = (xmax - xmin) / img_w\n",
    "        bh = (ymax - ymin) / img_h\n",
    "\n",
    "        gx = min(int(xc * GRID_SIZE), GRID_SIZE - 1)\n",
    "        gy = min(int(yc * GRID_SIZE), GRID_SIZE - 1)\n",
    "\n",
    "        label[gy, gx, 0:4] = [xc, yc, bw, bh]\n",
    "        label[gy, gx, 4] = 1.0\n",
    "        label[gy, gx, 5 + cls_id] = 1.0\n",
    "\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06438ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# DATASET LOADER (CLASS LIMITS)\n",
    "# =========================\n",
    "def load_dataset_custom_limits():\n",
    "    images, labels = [], []\n",
    "\n",
    "    CLASS_LIMITS = {\"bottle\": 800, \"person\": 500}\n",
    "    class_count = {cls: 0 for cls in CLASS_LIMITS}\n",
    "\n",
    "    files = [f for f in os.listdir(ANN_DIR) if f.endswith(\".xml\")]\n",
    "    np.random.shuffle(files)\n",
    "\n",
    "    for file in files:\n",
    "        if all(class_count[c] >= CLASS_LIMITS[c] for c in CLASS_LIMITS):\n",
    "            break\n",
    "\n",
    "        xml_path = os.path.join(ANN_DIR, file)\n",
    "        img_path = os.path.join(IMG_DIR, file.replace(\".xml\", \".jpg\"))\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        present = set()\n",
    "        for obj in root.findall(\"object\"):\n",
    "            cls = obj.find(\"name\").text\n",
    "            if cls in CLASS_LIMITS:\n",
    "                present.add(cls)\n",
    "\n",
    "        if not any(class_count[c] < CLASS_LIMITS[c] for c in present):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        label = parse_xml(xml_path, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        for cls in present:\n",
    "            if class_count[cls] < CLASS_LIMITS[cls]:\n",
    "                class_count[cls] += 1\n",
    "\n",
    "    print(\"Final class distribution:\", class_count)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b826fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MODEL\n",
    "# =========================\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(GRID_SIZE * GRID_SIZE * (5 + NUM_CLASSES)),\n",
    "        layers.Reshape((GRID_SIZE, GRID_SIZE, 5 + NUM_CLASSES))\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316ee9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# LOSS & METRIC\n",
    "# =========================\n",
    "def detection_loss(y_true, y_pred):\n",
    "    box_loss = tf.reduce_mean(tf.square(y_true[..., :4] - y_pred[..., :4]))\n",
    "    obj_loss = tf.reduce_mean(tf.square(y_true[..., 4] - y_pred[..., 4]))\n",
    "    cls_loss = tf.reduce_mean(tf.square(y_true[..., 5:] - y_pred[..., 5:]))\n",
    "    return box_loss + obj_loss + cls_loss\n",
    "\n",
    "def objectness_accuracy(y_true, y_pred):\n",
    "    y_true_obj = tf.cast(y_true[..., 4] > 0.5, tf.float32)\n",
    "    y_pred_obj = tf.cast(y_pred[..., 4] > 0.5, tf.float32)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_true_obj, y_pred_obj), tf.float32))\n",
    "\n",
    "# =========================\n",
    "# IOU + mAP\n",
    "# =========================\n",
    "def iou(box1, box2):\n",
    "    x1_min, y1_min = box1[0]-box1[2]/2, box1[1]-box1[3]/2\n",
    "    x1_max, y1_max = box1[0]+box1[2]/2, box1[1]+box1[3]/2\n",
    "    x2_min, y2_min = box2[0]-box2[2]/2, box2[1]-box2[3]/2\n",
    "    x2_max, y2_max = box2[0]+box2[2]/2, box2[1]+box2[3]/2\n",
    "\n",
    "    inter = max(0, min(x1_max,x2_max)-max(x1_min,x2_min)) * \\\n",
    "            max(0, min(y1_max,y2_max)-max(y1_min,y2_min))\n",
    "\n",
    "    union = (x1_max-x1_min)*(y1_max-y1_min) + (x2_max-x2_min)*(y2_max-y2_min) - inter\n",
    "    return inter / (union + 1e-6)\n",
    "\n",
    "def decode_grid(output, conf=0.5):\n",
    "    boxes = []\n",
    "    for y in range(GRID_SIZE):\n",
    "        for x in range(GRID_SIZE):\n",
    "            cell = output[y, x]\n",
    "            if cell[4] > conf:\n",
    "                cls = np.argmax(cell[5:])\n",
    "                boxes.append([cell[0], cell[1], cell[2], cell[3], cls])\n",
    "    return boxes\n",
    "\n",
    "def compute_map(model, X_val, y_val):\n",
    "    aps = []\n",
    "    for cls in range(NUM_CLASSES):\n",
    "        TP=FP=FN=0\n",
    "        for img, gt in zip(X_val, y_val):\n",
    "            pred = model.predict(img[None], verbose=0)[0]\n",
    "            p = [b for b in decode_grid(pred) if b[4]==cls]\n",
    "            g = [b for b in decode_grid(gt, 0.1) if b[4]==cls]\n",
    "\n",
    "            matched=set()\n",
    "            for pb in p:\n",
    "                ok=False\n",
    "                for i,gb in enumerate(g):\n",
    "                    if i not in matched and iou(pb[:4],gb[:4])>0.5:\n",
    "                        TP+=1; matched.add(i); ok=True; break\n",
    "                if not ok: FP+=1\n",
    "            FN+=len(g)-len(matched)\n",
    "        aps.append(TP/(TP+FP+1e-6))\n",
    "    return np.mean(aps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d86e1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final class distribution: {'bottle': 800, 'person': 500}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# FPS\n",
    "# =========================\n",
    "def measure_fps(model, X, runs=100):\n",
    "    start=time.time()\n",
    "    for i in range(runs):\n",
    "        model.predict(X[i%len(X)][None], verbose=0)\n",
    "    return runs/(time.time()-start)\n",
    "\n",
    "# =========================\n",
    "# TRAINING\n",
    "# =========================\n",
    "X, y = load_dataset_custom_limits()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56521a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "256/256 [==============================] - 29s 48ms/step - loss: 0.0964 - objectness_accuracy: 0.9713 - val_loss: 0.0440 - val_objectness_accuracy: 0.9765\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0488 - objectness_accuracy: 0.9734 - val_loss: 0.0440 - val_objectness_accuracy: 0.9765\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0466 - objectness_accuracy: 0.9736 - val_loss: 0.0446 - val_objectness_accuracy: 0.9765\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0419 - objectness_accuracy: 0.9751 - val_loss: 0.0456 - val_objectness_accuracy: 0.9764\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0361 - objectness_accuracy: 0.9787 - val_loss: 0.0477 - val_objectness_accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0310 - objectness_accuracy: 0.9825 - val_loss: 0.0479 - val_objectness_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0270 - objectness_accuracy: 0.9862 - val_loss: 0.0480 - val_objectness_accuracy: 0.9761\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0241 - objectness_accuracy: 0.9888 - val_loss: 0.0482 - val_objectness_accuracy: 0.9761\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 11s 41ms/step - loss: 0.0217 - objectness_accuracy: 0.9908 - val_loss: 0.0482 - val_objectness_accuracy: 0.9761\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 0.0201 - objectness_accuracy: 0.9924 - val_loss: 0.0501 - val_objectness_accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba1e377df0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer=\"adam\", loss=detection_loss, metrics=[objectness_accuracy])\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd23eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL RESULTS =====\n",
      "mAP@0.5   : 0.0000\n",
      "FPS       : 18.30\n",
      "Model Size: 1088.24 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# EVALUATION\n",
    "# =========================\n",
    "map_score = compute_map(model, X_val, y_val)\n",
    "fps = measure_fps(model, X_val[:10])\n",
    "\n",
    "model.save(\"cnn_detector2.h5\")\n",
    "size_mb = os.path.getsize(\"cnn_detector2.h5\") / (1024*1024)\n",
    "\n",
    "print(\"\\n===== FINAL RESULTS =====\")\n",
    "print(f\"mAP@0.5   : {map_score:.4f}\")\n",
    "print(f\"FPS       : {fps:.2f}\")\n",
    "print(f\"Model Size: {size_mb:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
