{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f3b26d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.1\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "IMAGE_SIZE = 320\n",
    "GRID_SIZE = 10       # ðŸ”§ FIXED (10 was too sparse)\n",
    "CLASSES = [\"bottle\", \"person\",\"phone\"]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "IMG_DIR = r\"dataset\\ds\"\n",
    "ANN_DIR = r\"dataset\\ds_annotation\"\n",
    "\n",
    "# =========================\n",
    "# GPU CHECK\n",
    "# =========================\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# =========================\n",
    "# XML PARSER\n",
    "# =========================\n",
    "def parse_xml(xml_file, img_w, img_h):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    label = np.zeros((GRID_SIZE, GRID_SIZE, 5 + NUM_CLASSES), dtype=np.float32)\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        if cls not in CLASSES:\n",
    "            continue\n",
    "\n",
    "        cls_id = CLASSES.index(cls)\n",
    "        box = obj.find(\"bndbox\")\n",
    "\n",
    "        xmin = int(box.find(\"xmin\").text)\n",
    "        ymin = int(box.find(\"ymin\").text)\n",
    "        xmax = int(box.find(\"xmax\").text)\n",
    "        ymax = int(box.find(\"ymax\").text)\n",
    "\n",
    "        xc = ((xmin + xmax) / 2) / img_w\n",
    "        yc = ((ymin + ymax) / 2) / img_h\n",
    "        bw = (xmax - xmin) / img_w\n",
    "        bh = (ymax - ymin) / img_h\n",
    "\n",
    "        gx = min(int(xc * GRID_SIZE), GRID_SIZE - 1)\n",
    "        gy = min(int(yc * GRID_SIZE), GRID_SIZE - 1)\n",
    "\n",
    "        label[gy, gx, 0:4] = [xc, yc, bw, bh]\n",
    "        label[gy, gx, 4] = 1.0\n",
    "        label[gy, gx, 5 + cls_id] = 1.0\n",
    "\n",
    "    return label\n",
    "\n",
    "# =========================\n",
    "# DATASET LOADER (LIMITED)\n",
    "# =========================\n",
    "def load_dataset_custom_limits():\n",
    "    images, labels = [], []\n",
    "\n",
    "    CLASS_LIMITS = {\"bottle\": 30, \"person\": 30,\"phone\":30}\n",
    "    class_count = {c: 0 for c in CLASS_LIMITS}\n",
    "\n",
    "    files = [f for f in os.listdir(ANN_DIR) if f.endswith(\".xml\")]\n",
    "    np.random.shuffle(files)\n",
    "\n",
    "    for file in files:\n",
    "        if all(class_count[c] >= CLASS_LIMITS[c] for c in CLASS_LIMITS):\n",
    "            break\n",
    "\n",
    "        xml_path = os.path.join(ANN_DIR, file)\n",
    "        img_path = os.path.join(IMG_DIR, file.replace(\".xml\", \".jpg\"))\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        present = set()\n",
    "        for obj in root.findall(\"object\"):\n",
    "            if obj.find(\"name\").text in CLASS_LIMITS:\n",
    "                present.add(obj.find(\"name\").text)\n",
    "\n",
    "        if not any(class_count[c] < CLASS_LIMITS[c] for c in present):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        label = parse_xml(xml_path, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        for c in present:\n",
    "            if class_count[c] < CLASS_LIMITS[c]:\n",
    "                class_count[c] += 1\n",
    "\n",
    "    print(\"Class distribution:\", class_count)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# =========================\n",
    "# MODEL (SIZE FIXED)\n",
    "# =========================\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(256, 3, activation=\"relu\"),\n",
    "        layers.GlobalAveragePooling2D(),   # ðŸ”§ KEY FIX\n",
    "\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(GRID_SIZE * GRID_SIZE * (5 + NUM_CLASSES)),\n",
    "        layers.Reshape((GRID_SIZE, GRID_SIZE, 5 + NUM_CLASSES))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# LOSS (mAP FIX)\n",
    "# =========================\n",
    "def detection_loss(y_true, y_pred):\n",
    "    box_loss = tf.reduce_mean(tf.square(y_true[..., :4] - y_pred[..., :4]))\n",
    "\n",
    "    obj_loss = tf.reduce_mean(\n",
    "        tf.keras.losses.binary_crossentropy(\n",
    "            y_true[..., 4], y_pred[..., 4]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cls_loss = tf.reduce_mean(\n",
    "        tf.keras.losses.categorical_crossentropy(\n",
    "            y_true[..., 5:], y_pred[..., 5:]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return box_loss + obj_loss + cls_loss\n",
    "\n",
    "# =========================\n",
    "# IOU + mAP\n",
    "# =========================\n",
    "def iou(box1, box2):\n",
    "    x1_min, y1_min = box1[0]-box1[2]/2, box1[1]-box1[3]/2\n",
    "    x1_max, y1_max = box1[0]+box1[2]/2, box1[1]+box1[3]/2\n",
    "    x2_min, y2_min = box2[0]-box2[2]/2, box2[1]-box2[3]/2\n",
    "    x2_max, y2_max = box2[0]+box2[2]/2, box2[1]+box2[3]/2\n",
    "\n",
    "    inter = max(0, min(x1_max,x2_max)-max(x1_min,x2_min)) * \\\n",
    "            max(0, min(y1_max,y2_max)-max(y1_min,y2_min))\n",
    "\n",
    "    union = (x1_max-x1_min)*(y1_max-y1_min) + \\\n",
    "            (x2_max-x2_min)*(y2_max-y2_min) - inter\n",
    "\n",
    "    return inter / (union + 1e-6)\n",
    "\n",
    "def decode_grid(output, conf=0.3):\n",
    "    boxes = []\n",
    "    for y in range(GRID_SIZE):\n",
    "        for x in range(GRID_SIZE):\n",
    "            cell = output[y, x]\n",
    "            if cell[4] > conf:\n",
    "                cls = np.argmax(cell[5:])\n",
    "                boxes.append([cell[0], cell[1], cell[2], cell[3], cls])\n",
    "    return boxes\n",
    "\n",
    "def compute_map(model, X_val, y_val):\n",
    "    aps = []\n",
    "    for cls in range(NUM_CLASSES):\n",
    "        TP = FP = FN = 0\n",
    "        for img, gt in zip(X_val, y_val):\n",
    "            pred = model.predict(img[None], verbose=0)[0]\n",
    "\n",
    "            p = [b for b in decode_grid(pred) if b[4] == cls]\n",
    "            g = [b for b in decode_grid(gt, 0.1) if b[4] == cls]\n",
    "\n",
    "            matched = set()\n",
    "            for pb in p:\n",
    "                found = False\n",
    "                for i, gb in enumerate(g):\n",
    "                    if i not in matched and iou(pb[:4], gb[:4]) > 0.5:\n",
    "                        TP += 1\n",
    "                        matched.add(i)\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    FP += 1\n",
    "            FN += len(g) - len(matched)\n",
    "\n",
    "        aps.append(TP / (TP + FP + 1e-6))\n",
    "    return np.mean(aps)\n",
    "\n",
    "# =========================\n",
    "# FPS\n",
    "# =========================\n",
    "def measure_fps(model, X, runs=20):\n",
    "    model.predict(X[0][None], verbose=0)  # warm-up\n",
    "    start = time.time()\n",
    "    for i in range(runs):\n",
    "        model.predict(X[i % len(X)][None], verbose=0)\n",
    "    return runs / (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50d1e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {'bottle': 20, 'person': 20, 'phone': 20}\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 0.1995 - val_loss: 0.2084\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1814 - val_loss: 0.2062\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1930 - val_loss: 0.1514\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1953 - val_loss: 0.1380\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2051 - val_loss: 0.1377\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.2047 - val_loss: 0.1373\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.2042 - val_loss: 0.1502\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1937 - val_loss: 0.1493\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1933 - val_loss: 0.1492\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1931 - val_loss: 0.2022\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1828 - val_loss: 0.2027\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1933 - val_loss: 0.1496\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1933 - val_loss: 0.1497\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1933 - val_loss: 0.1503\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1932 - val_loss: 0.1500\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1931 - val_loss: 0.1493\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1929 - val_loss: 0.1490\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1929 - val_loss: 0.1487\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1929 - val_loss: 0.1490\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1929 - val_loss: 0.1494\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1928 - val_loss: 0.1493\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1928 - val_loss: 0.1494\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1928 - val_loss: 0.1492\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1930 - val_loss: 0.1487\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1928 - val_loss: 0.1490\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1929 - val_loss: 0.1493\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1928 - val_loss: 0.1494\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1928 - val_loss: 0.1494\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1929 - val_loss: 0.1493\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1928 - val_loss: 0.1490\n",
      "\n",
      "===== FINAL RESULTS =====\n",
      "mAP@0.5   : 0.0000\n",
      "FPS       : 24.85\n",
      "Model Size: 6.27 MB\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# TRAIN\n",
    "# =========================\n",
    "X, y = load_dataset_custom_limits()\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = build_model()\n",
    "model.compile(optimizer=\"adam\", loss=detection_loss)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,        # ðŸ”§ IMPORTANT\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# EVALUATE\n",
    "# =========================\n",
    "map_score = compute_map(model, X_val, y_val)\n",
    "fps = measure_fps(model, X_val[:5])\n",
    "\n",
    "model.save(\"cnn_detector_1.h5\")\n",
    "size_mb = os.path.getsize(\"cnn_detector_fixed.h5\") / (1024 * 1024)\n",
    "\n",
    "print(\"\\n===== FINAL RESULTS =====\")\n",
    "print(f\"mAP@0.5   : {map_score:.4f}\")\n",
    "print(f\"FPS       : {fps:.2f}\")\n",
    "print(f\"Model Size: {size_mb:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
